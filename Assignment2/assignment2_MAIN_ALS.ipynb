{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset from database\n",
    "def load_data(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Loaded database\")\n",
    "\n",
    "    c = conn.cursor()\n",
    "    print(\"Fetching data ...\")\n",
    "    c.execute('SELECT UserID, ItemID, Rating FROM example_table')\n",
    "    data = c.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    user_indices = []\n",
    "    item_indices = []\n",
    "    ratings_values = []\n",
    "\n",
    "    max_user_id = 0\n",
    "    max_item_id = 0\n",
    "\n",
    "    for user_id, item_id, rating in data:\n",
    "        user_indices.append(user_id)\n",
    "        item_indices.append(item_id)\n",
    "        ratings_values.append(rating)\n",
    "        #ratings_values.append(int(rating * 2)) # convert ratings to integers\n",
    "        max_user_id = max(max_user_id, user_id)\n",
    "        max_item_id = max(max_item_id, item_id)\n",
    "\n",
    "    user_indices = np.array(user_indices, dtype=np.int32)\n",
    "    item_indices = np.array(item_indices, dtype=np.int32)\n",
    "    #ratings_values = np.array(ratings_values, dtype=np.int32)\n",
    "    ratings_values = np.array(ratings_values, dtype=np.float32)\n",
    "\n",
    "    print(\"Max user id:\", max_user_id)\n",
    "    print(\"Max item id:\", max_item_id)\n",
    "\n",
    "    return user_indices, item_indices, ratings_values, max_user_id, max_item_id\n",
    "\n",
    "#def normalize_ids(indices):\n",
    "#    unique_ids, inverse_indices = np.unique(indices, return_inverse=True)\n",
    "#    id_map = {original_id: idx for idx, original_id in enumerate(unique_ids)}\n",
    "#    reverse_map = {idx: original_id for idx, original_id in enumerate(unique_ids)}\n",
    "#    num_unique = len(unique_ids)  # The total number of unique indices\n",
    "#    return inverse_indices, num_unique, id_map, reverse_map\n",
    "\n",
    "def normalize_indices(indices):\n",
    "    unique_ids = np.unique(indices)\n",
    "    id_to_norm = {id_: i for i, id_ in enumerate(unique_ids)}\n",
    "    norm_to_id = {i: id_ for i, id_ in enumerate(unique_ids)}\n",
    "    normalized_indices = np.vectorize(id_to_norm.get)(indices)\n",
    "    num_unique = len(unique_ids)  # Total number of unique indices\n",
    "    return normalized_indices, num_unique, id_to_norm, norm_to_id\n",
    "\n",
    "# split into train and validation sets\n",
    "def split_data(user_indices, item_indices, ratings, split_ratio=0.9):\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(len(ratings))\n",
    "    split_point = int(len(ratings) * split_ratio)\n",
    "    train_idx, val_idx = indices[:split_point], indices[split_point:]\n",
    "    \n",
    "    train_data = (user_indices[train_idx], item_indices[train_idx], ratings[train_idx])\n",
    "    val_data = (user_indices[val_idx], item_indices[val_idx], ratings[val_idx])\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded database\n",
      "Fetching data ...\n",
      "Max user id: 138493\n",
      "Max item id: 26744\n",
      "Number of users: 138493\n",
      "Number of items: 26690\n",
      "Train data size: 16753799\n",
      "Validation data size: 1861534\n",
      "All data size: 18615333\n"
     ]
    }
   ],
   "source": [
    "# impor dataset\n",
    "\n",
    "path_100k = '../../data/dataset1/train_100k.db'\n",
    "path_20M = '../../data/dataset2/train_20M.db'\n",
    "\n",
    "u, i, global_ratings, global_max_user_id, global_max_item_id = load_data(path_20M)\n",
    "\n",
    "# Normalize user and item indices\n",
    "global_user_indices, global_num_users, user_to_norm, norm_to_user = normalize_indices(u)\n",
    "global_item_indices, global_num_items, item_to_norm, norm_to_item = normalize_indices(i)\n",
    "\n",
    "#global_num_users = np.unique(global_user_indices)\n",
    "#global_num_items = np.unique(global_item_indices)\n",
    "\n",
    "\n",
    "print(\"Number of users:\", global_num_users)\n",
    "print(\"Number of items:\", global_num_items)\n",
    "\n",
    "train_data, val_data = split_data(global_user_indices, global_item_indices, global_ratings, split_ratio=0.9)\n",
    "all_data, _ = split_data(global_user_indices, global_item_indices, global_ratings, split_ratio=1)\n",
    "\n",
    "print(\"Train data size:\",train_data[0].size)\n",
    "print(\"Validation data size:\",val_data[0].size)\n",
    "print(\"All data size:\",all_data[0].size)\n",
    "\n",
    "# train_data[0] = user_indices\n",
    "# train_data[1] = item_indices\n",
    "# train_data[2] = ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE and Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE and predict methods\n",
    "def calculate_mae(actual, predicted):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - actual_ratings: np.array, the actual ratings.\n",
    "    - predicted_ratings: np.array, the predicted ratings.\n",
    "    \"\"\"\n",
    "    # calculate the absolute error between actual and predicted ratings\n",
    "    abs_err = np.abs(actual - predicted)\n",
    "    \n",
    "    # calculate the mean of these absolute errors\n",
    "    mae = np.mean(abs_err)\n",
    "    \n",
    "    return mae # /2\n",
    "\n",
    "# round prediction to nearest 0.5 in range [0.5, 5]\n",
    "def round_predictions(predictions):\n",
    "    rounded_predictions = np.round(predictions * 2) / 2\n",
    "    return np.clip(rounded_predictions, 0.5, 5.0)\n",
    "    #rounded_predictions = np.round(predictions)\n",
    "    #return np.clip(rounded_predictions, 1, 10)\n",
    "\n",
    "def predict(user_features, item_features, user_indices, item_indices):\n",
    "    predictions = np.array([np.dot(user_features[u], item_features[i]) for u, i in zip(user_indices, item_indices)])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(user_indices, item_indices, ratings, num_users, num_items, num_factors, alpha, beta, iterations):\n",
    "    # Initialize feature matrices\n",
    "    np.random.seed(42)\n",
    "    user_features = np.random.normal(0, 0.1, (num_users, num_factors))\n",
    "    item_features = np.random.normal(0, 0.1, (num_items, num_factors))\n",
    "\n",
    "    # SGD updates (only using training data)\n",
    "    for iteration in range(iterations): #tqdm(range(iterations), desc='SGD iterations', total=iterations):\n",
    "        for u, i, r in tqdm(zip(user_indices, item_indices, ratings), desc=f'SGD {iteration+1}/{iterations}', total=len(ratings)):\n",
    "            prediction = np.dot(user_features[u], item_features[i])\n",
    "            error = r - prediction\n",
    "\n",
    "            # Update rules for features\n",
    "            user_features_grad = -2 * error * item_features[i] + beta * user_features[u]\n",
    "            item_features_grad = -2 * error * user_features[u] + beta * item_features[i]\n",
    "\n",
    "            user_features[u] -= alpha * user_features_grad\n",
    "            item_features[i] -= alpha * item_features_grad\n",
    "\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 60 factors and alpha= 0.0075, beta= 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SGD 1/2: 100%|██████████| 16753799/16753799 [04:52<00:00, 57228.63it/s]\n",
      "SGD 2/2: 100%|██████████| 16753799/16753799 [04:49<00:00, 57938.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6359013587718516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST 100K\n",
    "num_factors = 60  # Latent factors\n",
    "alpha = 0.0075      # Learning rate\n",
    "beta = 0.03      # Regularization\n",
    "iterations = 10   # Number of iterations\n",
    "\n",
    "# Run SGD\n",
    "print(f\"Testing with {num_factors} factors and alpha= {alpha}, beta= {beta}\")\n",
    "sgd_user_features, sgd_item_features = sgd(train_data[0], train_data[1], train_data[2], global_num_users, global_num_items, num_factors, alpha, beta, iterations)\n",
    "sgd_predictions = predict(sgd_user_features, sgd_item_features, val_data[0], val_data[1])\n",
    "train_pred2 = round_predictions(sgd_predictions)\n",
    "\n",
    "truth_ratings = val_data[2]\n",
    "sgd_mae = calculate_mae(truth_ratings, train_pred2)\n",
    "print(f\"MAE:\", sgd_mae)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als(user_indices, item_indices, ratings, num_users, num_items, num_factors, lambda_reg, iterations):\n",
    "    # Initialize matrices\n",
    "    np.random.seed(42)\n",
    "    user_features = np.random.normal(0, 0.1, (num_users, num_factors))\n",
    "    item_features = np.random.normal(0, 0.1, (num_items, num_factors))\n",
    "    \n",
    "    # Precompute user and item interactions\n",
    "    interaction_matrix = np.zeros((num_users, num_items))\n",
    "    interaction_matrix[user_indices, item_indices] = ratings\n",
    "\n",
    "    # Regularization matrix\n",
    "    lambda_eye = lambda_reg * np.eye(num_factors)\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        # Update user features\n",
    "        for u in tqdm(range(num_users), desc=f'ALS {iteration+1}/{iterations} (users)', total=num_users):\n",
    "            item_idx = interaction_matrix[u, :] > 0\n",
    "            V = item_features[item_idx]\n",
    "            r_u = interaction_matrix[u, item_idx]\n",
    "            A_u = V.T @ V + lambda_eye\n",
    "            b_u = V.T @ r_u\n",
    "            user_features[u] = np.linalg.solve(A_u, b_u)\n",
    "\n",
    "        # Update item features\n",
    "        for i in tqdm(range(num_items), desc=f'ALS {iteration+1}/{iterations} (items)', total=num_items):\n",
    "            user_idx = interaction_matrix[:, i] > 0\n",
    "            U = user_features[user_idx]\n",
    "            r_i = interaction_matrix[user_idx, i]\n",
    "            A_i = U.T @ U + lambda_eye\n",
    "            b_i = U.T @ r_i\n",
    "            item_features[i] = np.linalg.solve(A_i, b_i)\n",
    "\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 20 factors and beta= 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:53<00:00, 2604.46it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:52<00:00, 114.69it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 4981.49it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.41it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 4955.78it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:42<00:00, 120.03it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5006.40it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:41<00:00, 120.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6262611910392182\n",
      "\n",
      "Testing with 40 factors and beta= 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3877.09it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:47<00:00, 117.56it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:33<00:00, 4169.32it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:48<00:00, 116.82it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4366.92it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:46<00:00, 118.04it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4409.34it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6673176530753668\n",
      "\n",
      "Testing with 60 factors and beta= 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:40<00:00, 3449.24it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.07it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:36<00:00, 3840.38it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:50<00:00, 115.75it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3857.91it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:50<00:00, 115.78it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:36<00:00, 3844.10it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:50<00:00, 115.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7021486043231012\n",
      "\n",
      "Testing with 80 factors and beta= 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:46<00:00, 2949.77it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.43it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3299.25it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.31it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3316.72it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:52<00:00, 114.74it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:42<00:00, 3296.85it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:52<00:00, 114.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7391570607896498\n",
      "\n",
      "Testing with 20 factors and beta= 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4379.47it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.55it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5079.18it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.47it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5057.18it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.40it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5060.30it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6083592886297\n",
      "\n",
      "Testing with 40 factors and beta= 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3886.12it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.17it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4419.44it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.23it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4438.82it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:46<00:00, 118.09it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:30<00:00, 4476.72it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:46<00:00, 117.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.639984013184825\n",
      "\n",
      "Testing with 60 factors and beta= 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:40<00:00, 3417.34it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:48<00:00, 117.03it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3855.65it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:48<00:00, 116.55it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3859.26it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.55it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3869.88it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6665980852350804\n",
      "\n",
      "Testing with 80 factors and beta= 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:45<00:00, 3034.61it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:52<00:00, 114.83it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3312.20it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.36it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3329.89it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:51<00:00, 115.05it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3303.70it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:51<00:00, 115.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.698452459100935\n",
      "\n",
      "Testing with 20 factors and beta= 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4377.89it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:42<00:00, 119.77it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5075.88it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:42<00:00, 119.75it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5067.92it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:42<00:00, 119.79it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5060.70it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6046027093783943\n",
      "\n",
      "Testing with 40 factors and beta= 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3895.77it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.39it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4426.79it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.25it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4432.16it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.41it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4456.71it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6344673264092947\n",
      "\n",
      "Testing with 60 factors and beta= 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:40<00:00, 3433.78it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:48<00:00, 116.90it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3865.77it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.53it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3860.49it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.21it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3892.51it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6604373060067664\n",
      "\n",
      "Testing with 80 factors and beta= 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:46<00:00, 2948.70it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:52<00:00, 114.68it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:42<00:00, 3276.40it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.15it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:42<00:00, 3287.89it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.18it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:42<00:00, 3296.08it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:54<00:00, 114.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6929392640693106\n",
      "\n",
      "Testing with 20 factors and beta= 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4363.52it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:42<00:00, 119.76it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5054.90it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.60it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5048.99it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.61it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5060.91it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:42<00:00, 119.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6013843958799571\n",
      "\n",
      "Testing with 40 factors and beta= 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3882.96it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.34it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4453.96it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:46<00:00, 118.03it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4412.82it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.27it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4400.51it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6308899004799268\n",
      "\n",
      "Testing with 60 factors and beta= 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:40<00:00, 3438.57it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:48<00:00, 116.74it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3867.88it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.53it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3852.08it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:48<00:00, 116.73it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3874.44it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6568883512200153\n",
      "\n",
      "Testing with 80 factors and beta= 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:47<00:00, 2945.69it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:52<00:00, 114.67it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3311.63it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.17it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:42<00:00, 3287.70it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:54<00:00, 114.01it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3311.74it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:54<00:00, 113.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6914952936664063\n",
      "\n",
      "Testing with 20 factors and beta= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4353.63it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.66it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5031.82it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.49it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5078.22it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.36it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:27<00:00, 5043.82it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:43<00:00, 119.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5983860622475872\n",
      "\n",
      "Testing with 40 factors and beta= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3888.78it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:46<00:00, 118.05it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4439.60it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:45<00:00, 118.13it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4422.65it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:46<00:00, 118.04it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:31<00:00, 4409.81it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:46<00:00, 118.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6289192139386119\n",
      "\n",
      "Testing with 60 factors and beta= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:40<00:00, 3419.34it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:48<00:00, 116.62it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:36<00:00, 3833.39it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:49<00:00, 116.33it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3851.69it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:50<00:00, 115.95it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:35<00:00, 3852.45it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:50<00:00, 115.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6564825031398835\n",
      "\n",
      "Testing with 80 factors and beta= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/4 (users): 100%|██████████| 138493/138493 [00:47<00:00, 2926.54it/s]\n",
      "ALS 1/4 (items): 100%|██████████| 26690/26690 [03:52<00:00, 114.92it/s]\n",
      "ALS 2/4 (users): 100%|██████████| 138493/138493 [00:42<00:00, 3285.78it/s]\n",
      "ALS 2/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.54it/s]\n",
      "ALS 3/4 (users): 100%|██████████| 138493/138493 [00:41<00:00, 3311.89it/s]\n",
      "ALS 3/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.52it/s]\n",
      "ALS 4/4 (users): 100%|██████████| 138493/138493 [00:42<00:00, 3288.36it/s]\n",
      "ALS 4/4 (items): 100%|██████████| 26690/26690 [03:53<00:00, 114.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6958073287944244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "iterations = 4\n",
    "for beta in [0.005, 0.05, 0.1, 0.2, 0.5]:\n",
    "        for num_factors in [20, 40, 60, 80]:\n",
    "            print(f\"Testing with {num_factors} factors and beta= {beta}\")\n",
    "            als_user_features, als_item_features = als(train_data[0], train_data[1], train_data[2], global_num_users, global_num_items, num_factors, beta, iterations)\n",
    "            als_predictions = predict(als_user_features, als_item_features, val_data[0], val_data[1])\n",
    "            als_rounded = round_predictions(als_predictions)\n",
    "\n",
    "            truth_ratings = val_data[2]\n",
    "            als_mae = calculate_mae(truth_ratings, als_rounded)\n",
    "            print(f\"MAE:\", als_mae)            \n",
    "            print()\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set and Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded database\n",
      "Fetching data ...\n",
      "Missing IDs: {22144, 23296, 24321, 24961, 18693, 20103, 20615, 25353, 18955, 24715, 21904, 16145, 24976, 19731, 12054, 10648, 24985, 21532, 23068, 25894, 22316, 14382, 24244, 20283, 16189, 25663, 25280, 24769, 24642, 26692, 25289, 26569, 25292, 23502, 13906, 20179, 22482, 25691, 24284, 24796, 21598, 23009, 24803, 24294, 23278, 16751, 22127, 22129, 25329, 26357, 15862, 25978, 21499, 23676}\n",
      "Test data size:  1384930\n",
      "All data size:  18615333\n",
      "Ratio All Data / Test: 0.07439727239904868\n",
      "Ratio Train / Val: 0.11111115753507607\n",
      "Num users: 138493\n",
      "Num items: 12864\n"
     ]
    }
   ],
   "source": [
    "# import test set\n",
    "\n",
    "# load test set\n",
    "def load_test(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Loaded database\")\n",
    "\n",
    "    c = conn.cursor()\n",
    "    print(\"Fetching data ...\")\n",
    "    c.execute('SELECT UserID, ItemID, TimeStamp FROM example_table')\n",
    "    data = c.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    test_user_indices, test_item_indices, timestamps = zip(*data)\n",
    "\n",
    "    return np.array(test_user_indices, dtype=np.int32), np.array(test_item_indices, dtype=np.int32), np.array(timestamps, dtype=np.int32)\n",
    "\n",
    "def vectorize_indices(indices, mapping):\n",
    "    missing_ids = [id for id in indices if id not in mapping]\n",
    "    if missing_ids:\n",
    "        print(f\"Missing IDs: {set(missing_ids)}\")\n",
    "    \n",
    "    vectorized_indices = np.array([mapping[id] if id in mapping else -1 for id in indices])\n",
    "\n",
    "    return vectorized_indices, set(missing_ids)\n",
    "\n",
    "# 20M dataset\n",
    "test_dir_20M = '../../data/dataset2/test_20M.db'\n",
    "\n",
    "# 100k dataset\n",
    "test_dir_100K = '../../data/dataset1/test_100k.db'\n",
    "\n",
    "   \n",
    "# Load the dataset (excluding the header if present)\n",
    "test_user_indices, test_item_indices, timestamps = load_test(test_dir_20M)\n",
    "test_data = (test_user_indices, test_item_indices, timestamps)\n",
    "\n",
    "test_user_indices_normalized, missing_users = vectorize_indices(test_user_indices, user_to_norm)\n",
    "test_item_indices_normalized, missing_items = vectorize_indices(test_item_indices, item_to_norm)\n",
    "\n",
    "print(\"Test data size: \", len(test_data[0]))\n",
    "print(\"All data size: \", len(all_data[0]))\n",
    "print(\"Ratio All Data / Test:\", len(test_data[0]) / len(all_data[0]))\n",
    "print(\"Ratio Train / Val:\", len(val_data[0]) / len(train_data[0]))\n",
    "\n",
    "print(\"Num users:\", len(np.unique(test_user_indices_normalized)))\n",
    "print(\"Num items:\", len(np.unique(test_item_indices_normalized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SGD 1/10: 100%|██████████| 18615333/18615333 [05:26<00:00, 57013.58it/s]\n",
      "SGD 2/10: 100%|██████████| 18615333/18615333 [05:24<00:00, 57356.15it/s]\n",
      "SGD 3/10: 100%|██████████| 18615333/18615333 [05:22<00:00, 57719.38it/s]\n",
      "SGD 4/10: 100%|██████████| 18615333/18615333 [05:22<00:00, 57795.14it/s]\n",
      "SGD 5/10: 100%|██████████| 18615333/18615333 [05:23<00:00, 57576.29it/s]\n",
      "SGD 6/10: 100%|██████████| 18615333/18615333 [05:25<00:00, 57118.77it/s]\n",
      "SGD 7/10: 100%|██████████| 18615333/18615333 [05:27<00:00, 56886.83it/s]\n",
      "SGD 8/10: 100%|██████████| 18615333/18615333 [05:26<00:00, 57006.30it/s]\n",
      "SGD 9/10: 100%|██████████| 18615333/18615333 [05:28<00:00, 56621.14it/s]\n",
      "SGD 10/10: 100%|██████████| 18615333/18615333 [05:29<00:00, 56578.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run SGD on all data\n",
    "#num_factors = 20  # Latent factors\n",
    "#alpha = 0.0075      # Learning rate\n",
    "#beta = 0.125       # Regularization\n",
    "#iterations = 20 \n",
    "\n",
    "num_factors = 200  # Latent factors\n",
    "alpha = 0.005      # Learning rate\n",
    "beta = 0.03      # Regularization\n",
    "iterations = 100  # Number of iterations\n",
    "\n",
    "sgd_user_factors, sgd_item_factors = sgd(all_data[0], all_data[1], all_data[2], global_num_users, global_num_items, num_factors, alpha, beta, iterations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als(user_indices, item_indices, ratings, num_users, num_items, num_factors, lambda_reg, iterations):\n",
    "    # Initialize matrices\n",
    "    np.random.seed(42)\n",
    "    user_features = np.random.normal(0, 0.1, (num_users, num_factors))\n",
    "    item_features = np.random.normal(0, 0.1, (num_items, num_factors))\n",
    "    \n",
    "    # Precompute user and item interactions\n",
    "    interaction_matrix = np.zeros((num_users, num_items))\n",
    "    interaction_matrix[user_indices, item_indices] = ratings\n",
    "\n",
    "    # Regularization matrix\n",
    "    lambda_eye = lambda_reg * np.eye(num_factors)\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        # Update user features\n",
    "        for u in tqdm(range(num_users), desc=f'ALS {iteration+1}/{iterations} (users)', total=num_users):\n",
    "            item_idx = interaction_matrix[u, :] > 0\n",
    "            V = item_features[item_idx]\n",
    "            r_u = interaction_matrix[u, item_idx]\n",
    "            A_u = V.T @ V + lambda_eye\n",
    "            b_u = V.T @ r_u\n",
    "            user_features[u] = np.linalg.solve(A_u, b_u)\n",
    "\n",
    "        # Update item features\n",
    "        for i in tqdm(range(num_items), desc=f'ALS {iteration+1}/{iterations} (items)', total=num_items):\n",
    "            user_idx = interaction_matrix[:, i] > 0\n",
    "            U = user_features[user_idx]\n",
    "            r_i = interaction_matrix[user_idx, i]\n",
    "            A_i = U.T @ U + lambda_eye\n",
    "            b_i = U.T @ r_i\n",
    "            item_features[i] = np.linalg.solve(A_i, b_i)\n",
    "\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALS 1/1 (users): 100%|██████████| 138493/138493 [00:58<00:00, 2366.96it/s]\n",
      "ALS 1/1 (items):  55%|█████▍    | 14597/26690 [02:03<01:43, 117.35it/s]"
     ]
    }
   ],
   "source": [
    "num_factors = 60  # Latent factors\n",
    "lambda_reg = 0.1 # Regularization\n",
    "iterations = 1   # Number of iterations\n",
    "\n",
    "\n",
    "als_user_features, als_item_features = als(train_data[0], train_data[1], train_data[2], global_num_users, global_num_items, num_factors, beta, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_predictions = predict(als_user_features, als_item_features, val_data[0], val_data[1])\n",
    "als_rounded = round_predictions(als_predictions)\n",
    "\n",
    "truth_ratings = val_data[2]\n",
    "als_mae = calculate_mae(truth_ratings, als_rounded)\n",
    "print(f\"MAE:\", als_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prediction_value = 3 # Midpoint between 0.5 and 5.0, adjust as needed\n",
    "\n",
    "# Assuming you have a function `make_predictions` that uses your model\n",
    "predictions = predict(sgd_user_factors, sgd_item_factors, test_user_indices_normalized, test_item_indices_normalized)\n",
    "\n",
    "# Replace predictions for missing indices with the default value\n",
    "predictions[test_item_indices_normalized == -1] = default_prediction_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realign_predictions(original_user_indices, original_item_indices, normalized_user_indices, normalized_item_indices, predictions, default_value=3.0):\n",
    "    # Initialize the aligned predictions array with the default value\n",
    "    aligned_predictions = np.full(original_user_indices.shape, default_value, dtype=float)\n",
    "\n",
    "    # Create a mapping from normalized indices back to original positions\n",
    "    # This map should be built from the normalized indices, not from the original indices directly.\n",
    "    norm_to_orig_map = {}\n",
    "    for idx, (norm_u, norm_i) in enumerate(zip(normalized_user_indices, normalized_item_indices)):\n",
    "        if (norm_u, norm_i) not in norm_to_orig_map:  # avoid overriding if multiple original indices map to the same normalized index\n",
    "            norm_to_orig_map[(norm_u, norm_i)] = idx\n",
    "\n",
    "    # Use this map to assign predictions to their corresponding original indices\n",
    "    for idx in range(len(predictions)):\n",
    "        norm_u = normalized_user_indices[idx]\n",
    "        norm_i = normalized_item_indices[idx]\n",
    "        if (norm_u, norm_i) in norm_to_orig_map:\n",
    "            orig_idx = norm_to_orig_map[(norm_u, norm_i)]\n",
    "            aligned_predictions[orig_idx] = predictions[idx]\n",
    "\n",
    "    return aligned_predictions\n",
    "\n",
    "# Now call this function to realign your predictions\n",
    "aligned_predictions = realign_predictions(test_user_indices, test_item_indices, test_user_indices_normalized, test_item_indices_normalized, predictions)\n",
    "\n",
    "# Round the predictions to the nearest 0.5\n",
    "final_predictions = round_predictions(aligned_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_csv(user_ids, item_ids, predictions, timestamps, filename):\n",
    "    # Ensure all parts are numpy arrays (in case they are not)\n",
    "    user_ids = np.array(user_ids)\n",
    "    item_ids = np.array(item_ids)\n",
    "    predictions = np.array(predictions)\n",
    "    timestamps = np.array(timestamps)\n",
    "    \n",
    "    # Stack the arrays horizontally\n",
    "    data_to_save = np.column_stack((user_ids, item_ids, predictions, timestamps))\n",
    "        \n",
    "    # Save to CSV\n",
    "    np.savetxt(filename, data_to_save, delimiter=',', fmt='%d,%d,%.1f,%d')\n",
    "\n",
    "path = 'Official_submission/results3.csv'\n",
    "save_predictions_to_csv(test_user_indices, test_item_indices, final_predictions, timestamps, path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soc-cmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
